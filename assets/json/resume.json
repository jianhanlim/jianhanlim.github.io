{"$schema":"https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json","basics":{"name":"Jian Han Lim","label":"PhD | Chief Data Scientist at Pulses AI","image":"","email":"jianhanl@hotmail.com","phone":"","url":"","summary":"Experienced ML/AI Engineer with a demonstrated history of working in the artificial intelligence (computer vision & NLP) industry.\n\nI have a PhD degree from the Faculty of Computer Science and Information Technology, Universiti Malaya (UM), Malaysia.\n\nContact me via this email jianhanl98@gmail.com.","location":{"countryCode":"US","address":"Malaysia"},"profiles":[{"network":"LinkedIn","username":"jian-han-lim-8469b5a4","url":"https://www.linkedin.com/in/jian-han-lim-8469b5a4/"}]},"work":[{"name":"Pulses AI","position":"Chief Data Scientist","startDate":"2021-09-30","endDate":"","highlights":[],"summary":null,"url":"https://www.linkedin.com/company/18944255","location":null},{"name":"Upwork","position":"Freelance Software Engineer | Machine Learning & Deep Learning Engineer","startDate":"2015-05-31","endDate":"","highlights":[],"summary":"- Top Rated Freelancer and 100% Job Success in Upwork.\n- Worked as a freelance web developer in designing and developing ASP.NET Web Application and Java Desktop Application. I am also worked as machine learning and deep learning engineer, focusing on using deep learning techniques to solve computer vision problem in python, tensorflow, keras, etc.","url":"https://www.linkedin.com/company/4827017","location":null},{"name":"University of Malaya","position":"Research Assistant","startDate":"2018-01-31","endDate":"2021-08-31","highlights":[],"summary":"Worked as a research assistant in Multimedia Signal Processing Lab to adopt machine learning and deep learning skills to work on computer vision field","url":"","location":"Kuala Lumpur, Malaysia"},{"name":"Cancer Research Malaysia","position":"Research Assistant","startDate":"2019-01-31","endDate":"2019-04-30","highlights":[],"summary":"Cancer Research Malaysia seeks to utilize my skill and expertise in artificial intelligence to assist in developing an AI-driven tool for the early detection of oral cancer. This is a 4 months short term contract to ensure all relevant AI works are completed on schedule.","url":"https://www.linkedin.com/company/8833624","location":"Selangor, Malaysia"},{"name":"Syscatech Sdn Bhd","position":"Software Engineer","startDate":"2017-02-28","endDate":"2017-11-30","highlights":[],"summary":"•\tWorked as a Java programmer in developing web application using JSP & Servlet, MySQL and tomcat.\n•\tInvolved in designing Website using Bootstrap Framework.","url":"","location":"Cheras"}],"volunteer":[],"education":[{"institution":"University of Malaya","area":"Artificial Intelligence","studyType":"Doctor of Philosophy - PhD","startDate":"2018-09-30","endDate":"2023-12-31","score":"","courses":[]},{"institution":"Campbell University","area":"Computer Software Engineering","studyType":"Bachelor of Applied Science - BASc","startDate":"2015-12-31","endDate":"2017-12-31","score":"3.988","courses":[]},{"institution":"Tunku Abdul Rahman University College","area":"Computer Software Engineering","studyType":"Bachelor of Software engineering","startDate":"2015-12-31","endDate":"2017-12-31","score":"3.9623","courses":[]}],"awards":[{"title":"Won Best Student Paper Award in 25th Conference on Medical Image Understanding and Analysis (MIUA2021)","date":"2021-07-31","awarder":"MIUA2021","summary":"MIUA is a UK-based international conference for the communication of image processing and analysis research and its application to medical imaging and biomedicine. This is a rapidly growing subject with ever-increasing real-world applicability. Our paper is accepted and selected as the best student paper at the conference.\n\nPresentation video is available at https://youtu.be/Nmy3PZM5liQ"},{"title":"Won in Perfect Corp. AI Meets Beauty Challenge","date":"2018-10-31","awarder":"Perfect Corp., CyberLink Corp., and National Chiao Tung University","summary":"Perfect Corp. “AI Meets Beauty Challenge” attracted the brightest minds in artificial intelligence (AI) development, attracting 97 teams from 13 countries around the world. After months of intense competition and a rigorous selection process, my team was awarded as top 4 position in this challenge over 97 teams.\n\nLink: https://www.businesswire.com/news/home/20181025005400/en/Perfect-Corp.-Honors-Innovative-Winners"},{"title":"PECIPTA 2017 Silver Award","date":"2017-10-31","awarder":"Ministry of Higher Education, Malaysia","summary":"Won Silver Award at the International Conference and Exposition on Inventions by Institutions of Higher Learning (PECIPTA). It is a biannual program organised by the Ministry of Higher Education, Malaysia together with its partner institution science since 2001. PECIPTA aims to showcase innovative products and services from institutions of higher learning (IHL)."},{"title":"The Wallace Ewart Prize","date":"2017-10-31","awarder":"Campbell University","summary":"The Wallace Ewart Prize is awarded to the students, who, upon having completed the requirements for the award of the Degree of Bachelor of Science of Campbell University, is selected by the Dean and Faculty as the most outstanding student of the Computer Science Class considering academic achievement, character, integrity and leadership potential."},{"title":"1st Prize in Hack2Hired Software Hackathon 2017","date":"2017-04-30","awarder":"DreamCatcher","summary":"Won 1st Prize in 2 Hours Java Category Individual Programming Competition involving 100 ++ participants."},{"title":"3rd Prize in Hack2Hired Software Hackathon 2017","date":"2017-04-30","awarder":"DreamCatcher","summary":"Won 3rd Prize in 28 Hours non-stop Group Programming Competition."},{"title":"1st Prize in Final Year Project Competition 2016","date":"2016-12-31","awarder":"Tunku Abdul Rahman University College","summary":"This is a Final Year Project Competition held during Wi-Me 2.0 2016 at Tunku Abdul Rahman University College involving 30 ++ groups of final year students."},{"title":"3rd Prize in Openet Cash4Code Programming Competition 2016","date":"2016-07-31","awarder":"Openet","summary":"The OPENET CASH4CODE 2016 Competition requires students who were eagerly waiting to work their brains and create solutions for the competition’s challenge. Within a two-hour time frame, the students were required to compose their answer using the programming language of Java or C++."},{"title":"2nd Prize in eGenting Programming Competition 2015","date":"2015-11-30","awarder":"E-Genting","summary":"The E-Genting Programming Competition is an annual programming competition organised by E-Genting which requires participant to complete the programming questions using hand-written in 8 hours without accessing to electronic devices or internet."}],"certificates":[{"name":"TRIZ LEVEL 1 FOR PRACTITIONERS\n","issuer":"The Malaysia TRIZ Innovation Association"},{"name":"Machine Learning","issuer":"Coursera","startDate":"2018-04-30","url":"https://www.coursera.org/account/accomplishments/verify/LVQVU9KHR5B5"},{"name":"Neural Networks and Deep Learning","issuer":"Coursera","startDate":"2018-06-30","url":"https://www.coursera.org/account/accomplishments/verify/R2GRAEKY5MK7"},{"name":"Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization","issuer":"Coursera","startDate":"2018-07-31","url":"https://www.coursera.org/account/accomplishments/verify/FY5A4QXRF3WE"},{"name":"Structuring Machine Learning Projects","issuer":"Coursera","startDate":"2018-07-31","url":"https://www.coursera.org/account/accomplishments/verify/HLT9Z6GYHQYV"},{"name":"Convolutional Neural Networks","issuer":"Coursera","startDate":"2018-09-30","url":"https://www.coursera.org/account/accomplishments/verify/SYBKQXW8BQYK"},{"name":"Sequence Models","issuer":"Coursera","startDate":"2018-10-31","url":"https://www.coursera.org/account/accomplishments/verify/JSPY8LBDQZ4A"},{"name":"Deep Learning Specialization","issuer":"Coursera","startDate":"2018-10-31","url":"https://www.coursera.org/account/accomplishments/specialization/B4M9Q9AHYFH2"}],"publications":[{"name":"Mask-guided network for image captioning","publisher":"Pattern Recognition Letters","releaseDate":"2023-08-07","summary":"Attention mechanisms have been widely adopted for image captioning because of their powerful performance. In this paper, we propose a Mask Captioning Network (MaC) consisting of an object layer and a background layer to capture the objects and scenes of an image to generate a sentence. To this end, we leverage the Mask RCNN to detect salient regions at the pixel level instead of a bounding box in the object layer. Meanwhile, in the background layer, a CNN model is used to encode the scene features. In addition, MaC is implemented in both LSTM-based and Transformer-based image captioning architectures. We introduce a mask-guided transformer encoder with additional features to enhance the model. Experimental results show that our model significantly outperforms (with a much richer sentence) baseline models and achieves comparable results with state-of-the-art methods on MSCOCO and Flickr30k datasets.","url":"https://www.sciencedirect.com/science/article/abs/pii/S0167865523002167"},{"name":"Protect, Show, Attend and Tell: Empowering Image Captioning Models with Ownership Protection","publisher":"Pattern Recognition","releaseDate":"2021-08-30","summary":"• We propose a key-based strategy that provides reliable, preventive and timely IP protection for image captioning task.\n\n• We empirically show the effectiveness of our approach against various attacks and prove the ownership of the model.\n\n• To the best of our knowledge, we are the first to propose IP protection on image captioning model.","url":"https://www.sciencedirect.com/science/article/abs/pii/S0031320321004659"},{"name":"D’OraCa: Deep Learning-Based Classification of Oral Lesions with Mouth Landmark Guidance for Early Detection of Oral Cancer","publisher":"Springer, Cham","releaseDate":"2021-07-12","summary":"Oral cancer is a major health issue among low- and middle-income countries due to the late diagnosis. Automated algorithms and tools have the potential to identify oral lesions for early detection of oral cancer. In this paper, we aim to develop a novel deep learning framework named D’OraCa to classify oral lesions using photographic images. We are the first to develop a mouth landmark detection model for the oral images and incorporate it into the oral lesion classification model as a guidance to improve the classification accuracy. We evaluate the performance of five different deep convolutional neural networks and MobileNetV2 was chosen as the feature extractor for our proposed mouth landmark detection model. Quantitative and qualitative results demonstrate the effectiveness of the mouth landmark detection model in guiding the classification model to classify the oral lesions into four different referral decision classes. We train our proposed mouth landmark model on a combination of five datasets, containing 221,565 images. Then, we train and evaluate our proposed classification model with mouth landmark guidance using 2,455 oral images. The results are consistent with clinicians and the   𝐹1  score of the classification model is improved to 61.68%.","url":"https://link.springer.com/chapter/10.1007/978-3-030-80432-9_31"},{"name":"Fine-Tuning Deep Learning Architectures for Early Detection of Oral Cancer","publisher":"International Symposium on Mathematical and Computational Oncology (ISMCO)","releaseDate":"2020-12-07","summary":"Oral cancer is most prevalent in low- and middle-income countries where it is associated with late diagnosis. A significant factor for this is the limited access to specialist diagnosis. The use of artificial intelligence for decision making on oral cavity images has the potential to improve cancer management and survival rates. This study forms part of the MeMoSA® (Mobile Mouth Screening Anywhere) project. In this paper, we extended on our previous deep learning work and focused on the binary image classification of ‘referral’ vs. ‘non-referral’. Transfer learning was applied, with several common pre-trained deep convolutional neural network architectures compared for the task of fine-tuning to a small oral image dataset. Improvements to our previous work were made, with an accuracy of 80.88% achieved and a corresponding sensitivity of 85.71% and specificity of 76.42%.","url":"https://link.springer.com/chapter/10.1007/978-3-030-64511-3_3"},{"name":"Protect, Show, Attend and Tell: Image Captioning Model with Ownership Protection","publisher":"arXiv preprint","releaseDate":"2020-08-25","summary":"By and large, existing Intellectual Property Right (IPR) protection on deep neural networks typically i) focus on image classification task only, and ii) follow a standard digital watermarking framework that were conventionally used to protect the ownership of multimedia and video content. This paper demonstrates that current digital watermarking framework is insufficient to protect image captioning task that often regarded as one of the frontier A.I. problems. As a remedy, this paper studies and proposes two different embedding schemes in the hidden memory state of a recurrent neural network to protect image captioning model. From both theoretically and empirically points, we prove that a forged key will yield an unusable image captioning model, defeating the purpose on infringement. To the best of our knowledge, this work is the first to propose ownership protection on image captioning task. Also, extensive experiments show that the proposed method does not compromise the original image captioning performance on all common captioning metrics on Flickr30k and MS-COCO datasets, and at the same time it is able to withstand both removal and ambiguity attacks.","url":"https://arxiv.org/abs/2008.11009"},{"name":"Automated detection and classification of oral lesions using deep learning for early detection of oral cancer","publisher":"IEEE Access","releaseDate":"2020-07-20","summary":"Oral cancer is a major global health issue accounting for 177,384 deaths in 2018 and it is most prevalent in low- and middle-income countries. Enabling automation in the identification of potentially malignant and malignant lesions in the oral cavity would potentially lead to low-cost and early diagnosis of the disease. Building a large library of well-annotated oral lesions is key. As part of the MeMoSA ® (Mobile Mouth Screening Anywhere) project, images are currently in the process of being gathered from clinical experts from across the world, who have been provided with an annotation tool to produce rich labels. A novel strategy to combine bounding box annotations from multiple clinicians is provided in this paper. Further to this, deep neural networks were used to build automated systems, in which complex patterns were derived for tackling this difficult task. Using the initial data gathered in this study, two deep learning based computer vision approaches were assessed for the automated detection and classification of oral lesions for the early detection of oral cancer, these were image classification with ResNet-101 and object detection with the Faster R-CNN. Image classification achieved an F1 score of 87.07% for identification of images that contained lesions and 78.30% for the identification of images that required referral. Object detection achieved an F1 score of 41.18% for the detection of lesions that required referral. Further performances are reported with respect to classifying according to the type of referral decision. Our initial results demonstrate deep learning has the potential to tackle this challenging task.","url":"https://ieeexplore.ieee.org/document/9144177"},{"name":"Mask Captioning Network","publisher":"IEEE International Conference on Image Processing (ICIP)","releaseDate":"2019-05-01","summary":"Nowadays, attention mechanisms have been widely adopted in image captioning task due to its outstanding performance. In this paper, we propose a Mask Captioning Network (MaC) that consists of an object layer and a background layer to capture the objects and scene of an image, independently to generate a much richer sentence. To this end, we leverage on Mask RCNN to detect the salient regions in pixel level in the object layer; while, in the background layer, a CNN model is used to encode the scene features. Experimental results show that our model significantly outperforms baseline models and achieves comparable results with the state-of-the-art methods on MSCOCO and Flickr30k datasets.","url":"https://ieeexplore.ieee.org/document/8803004"},{"name":"Unprecedented Usage of Pre-trained CNNs on Beauty Product","publisher":"ACM Multimedia Conference 2018","releaseDate":"2018-10-21","summary":"How does a pre-trained Convolution Neural Network (CNN) model perform on beauty and personal care items (i.e Perfect-500K) This is the question we attempt to answer in this paper by adopting several well known deep learning models pre-trained on ImageNet, and evaluate their performance using different distance metrics. In the Perfect Corp Challenge, we manage to secure fourth position by using only the pre-trained model.","url":"https://dl.acm.org/doi/10.1145/3240508.3266433"},{"name":"Automated classroom monitoring with connected visioning system","publisher":"Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), 2017","releaseDate":"2017-12-12","summary":"Internet of Things (IoT) with the concept of integrating connectivity, sensors, data analysis and decision making in an underlying framework has ease many real world problems. In this work, we study the application of IoT for education purpose. Student's behavior and performance in the class is always the main concern of every educator. The instructors are responsible to ensure the smoothness of the classroom activities alongside with monitoring the students' attendance, attention, and activities like entering or leaving the classroom. Manual observation on these could affect the teaching and learning process and causes the distraction from the main syllabus. With the incorporation of IoT devices and computational algorithms such as computer vision techniques, machine learning and data analysis, it can ease the monitoring task and the analysis of students' performance in the class. In advance, it can perform automated real-time observation on the student's behavior through network and react immediately to critical situation if necessary. Nonetheless, the students' long- term performance can be recorded and the data can be used for continuous assessment in the future. In this work, we propose an IoT framework that focused on three analysis modules: face recognition, motion analysis, and behaviour understanding to effectively perform classroom monitoring tasks such as taking attendance, identify entering and leaving activities and analyse the students concentration level.","url":"https://ieeexplore.ieee.org/document/8282063"}],"skills":[{"name":"Java","level":"","keywords":[]},{"name":"Ionic Framework","level":"","keywords":[]},{"name":"Web Development","level":"","keywords":[]},{"name":"Bootstrap","level":"","keywords":[]},{"name":"Keras","level":"","keywords":[]},{"name":"Machine Learning","level":"","keywords":[]},{"name":"Responsive Web Design","level":"","keywords":[]},{"name":"TensorFlow","level":"","keywords":[]},{"name":"Web Services","level":"","keywords":[]},{"name":"Python","level":"","keywords":[]},{"name":"SQL","level":"","keywords":[]},{"name":"Artificial Neural Networks","level":"","keywords":[]},{"name":"Deep Learning","level":"","keywords":[]},{"name":"ASP.NET","level":"","keywords":[]},{"name":"Motion Analysis","level":"","keywords":[]}],"languages":[{"fluency":"Native Speaker","language":"Chinese"},{"fluency":"Full Professional","language":"English"},{"fluency":"Professional Working","language":"Malay"}],"interests":[],"references":[],"projects":[{"name":"Smart Classroom Management System","startDate":"2016-02-28","summary":"•\tDevelop an automated system integrated with connected camera and computer vision based processing unit to assist the instructor in managing classroom activities.\n•\tInvolved in Face Recognition, Human Tracking and Motion Analysis techniques to recognize, track and analyze the behavior of students in classroom\n","url":null,"endDate":"2016-12-31"},{"name":"Document Management System","startDate":"2016-01-31","summary":"•\tWorked as freelancer and developed an ASP.NET web application project for a company to reduce the load on their mail server by allowing admin to create, edit, delete webpage content, send document to their staff and access by their staff. ","url":null,"endDate":"2016-02-28"},{"name":"Furniture Management System","startDate":"2015-10-31","summary":"•\tThis is a college assignment project that includes four modules in this web application, which are maintenance module, stock management module, online/offline order and payment module, delivery and customer’s feedback module. I have integrated PayPal web service in this project to allow user make payment through PayPal.","url":null,"endDate":"2015-12-31"},{"name":"Customer Data Management System","startDate":"2015-06-30","summary":"•\tWorked as freelancer and developed a Java Desktop Application, which can integrate with Microsoft Excel to import/export data from/to excel to the system. \n•\tThe main function of this system is to remove duplicate customer data and centralize millions number of customer data. \n","url":null,"endDate":"2015-08-31"}],"meta":{"version":"v1.0.0","canonical":"https://github.com/jsonresume/resume-schema/blob/v1.0.0/schema.json"}}